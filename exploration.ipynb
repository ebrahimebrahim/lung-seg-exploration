{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9caddba5",
   "metadata": {},
   "source": [
    "*Attention U-Net Based Adversarial Architectures for Chest X-ray Lung Segmentation*\\\n",
    "2020 Gaal, Maga, Lukacs\\\n",
    "[link](https://arxiv.org/pdf/2003.10304.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f933a5",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "## Some publicly available datasets\n",
    "\n",
    "- [JSRT](https://www.ajronline.org/doi/pdf/10.2214/ajr.174.1.1740071)\n",
    "\t- 247 chest X-rays, 154 have lung nodules. Has lung and heart seg.\n",
    "\t- [Get here](http://db.jsrt.or.jp/eng.php) (register at bottom of page)\n",
    "- [Montgomery and Shenzhen](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/)\n",
    "\t- Montgomery contains 138 chest X-rays, 80 healthy, 58 tuberculosis. Has lung seg.\n",
    "\t- Shenzhen contains 662 chest X-rays, 326 healthy, 336 tuberculosis. Has lung seg.\n",
    "\t- [Get both here](https://openi.nlm.nih.gov/faq?it=xg#collection). Look for \"tuberculosis collection\"\n",
    "\n",
    "That’s 1047 images with lung segmentation label. There are larger datasets that have no segmentation label:\n",
    "\n",
    "- [NIH ChestX-ray8](https://arxiv.org/abs/1705.02315)\n",
    "\t- 108,948 CXRs of 32,717 patients with eight text-mined disease labels\n",
    "\t- [this might be a way to download](https://nihcc.app.box.com/v/ChestXray-NIHCC)\n",
    "- [NLST](https://www.nejm.org/doi/10.1056/NEJMoa1102873)\n",
    "\t- There's [this link](https://cdas.cancer.gov/publications/320/), which eventually leads [here](https://cdas.cancer.gov/datasets/nlst/), but I don't see any actual CXR images being made available.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8e455",
   "metadata": {},
   "source": [
    "### JSRT\n",
    "\n",
    "See [this guide](JSRT_UsersGuide.pdf) to the data for details.\n",
    "\n",
    "- `JPCLN***.IMG` for chest lung nodule images, and `JPCNN***.IMG` for non-nodule images. These are important classes to keep in mind for the purpose of proportional train/val/test split.\n",
    "-  coordinates of the upper left of the image are `(0,0)`\n",
    "- Image type: 16-bit Unsigned\n",
    "- Width: 2048 pixels\n",
    "- Height: 2048 pixels\n",
    "- Offset to First Image: 0 bytes\n",
    "- Gap Between Images: 0 bytes\n",
    "\n",
    "You can load the images using [ImageJ](https://imagej.nih.gov/ij/).\n",
    "Just import as \"RAW\" and put in the settings specified by the JSRT guide.\n",
    "\n",
    "Hmm, stuck on this for now... also where are the segmentations? When I load RAW data into Image J I only see an xray image, and I see no reference to segmentation in the JSRT guide. The JSRT download page doesn't say anything about segmentation labels either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f0734",
   "metadata": {},
   "source": [
    "### Shenzhen\n",
    "\n",
    "[The readme](NLM-ChinaCXRSet-ReadMe.pdf).\n",
    "\n",
    "- 336 cases with manifestation of tuberculosis, and \n",
    "- 326 normal cases.\n",
    "\n",
    "- Format: PNG\n",
    "- Image size varies for each X-ray. It is approximately 3K x 3K.\n",
    "\n",
    "- Image file names are coded as `CHNCXR_#####_0/1.png`, where ‘0’ represents the normal and ‘1’\n",
    "represents the abnormal lung. \n",
    "\n",
    "Hmm I also cannot find any lung segmentation for this. And [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/) that introduces the dataset seems to suggest that it's just the Montgomery set that has the segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6d7e7",
   "metadata": {},
   "source": [
    "### Montgomery\n",
    "\n",
    "[The readme](NLM-MontgomeryCXRSet-ReadMe.pdf).\n",
    "\n",
    "- 58 cases\twith\tmanifestation\tof\ttuberculosis,\tand\t 80 normal\tcases.\n",
    "- Image\t file\t names\tare\t coded\tas\t`MCUCXR_#####_0/1.png`, where\t‘0’\t represents\t the\t normal\tand\t‘1’ represents\tthe\tabnormal\tlung. These are important classes to keep in mind for the purpose of proportional train/val/test split.\n",
    "\n",
    "---\n",
    "\n",
    "- Format:\tPNG\n",
    "- Matrix\tsize\tis\t4020\tx\t4892,\tor\t4892\tx\t4020.\n",
    "- The\tpixel\tspacing\tin\tvertical\tand\thorizontal\tdirections\tis\t0.0875\tmm.\t\n",
    "- Number\tof\tgray\tlevels\tis\t12 bits.\n",
    "\n",
    "---\n",
    "\n",
    "Segmentation:\n",
    "> We\tmanually\tgenerated\tthe\t“gold\tstandard” segmentations\tfor\tthe\tchest\tX-ray\tunder\tthe\tsupervision\tof a\tradiologist.\tWe\tused\tthe\tfollowing\tconventions\tfor outlining\tthe\tlung\tboundaries:\tBoth\tposterior\tand\tanterior\tribs\tare\treadily\tvisible\tin\tthe\tCXRs;\tthe\tpart\tof\tthe\tlung\tbehind\tthe\theart\tis\texcluded.\tWe\tfollow\tanatomical\t landmarks\t such\t as\t the\t boundary\t of\t the\t heart,\t aortic\t arc/line,\t and\t pericardium\t line;\t and\tsharp\tcostophrenic\tangle\tthat\tfollow\tthe\tdiaphragm\tboundary. We\tdraw\tan\tinferred\tboundary\twhen\tthe\tpathology\tis\tsevere\tand\taffects\tthe\tmorphological\tappearance\tof\tthe\tlungs. The\tlung\tboundaries\t(left\tand\tright)\tare\tin\tbinary\timage\tformat\tand\thave\tthe\tsame\tfile\tname\tas\tchest\tXrays\t( e.g.\t`…/left/MCUCXR_#####_0/1.png` or\t`…/right/MCUCXR_#####_0/1.png`). \n",
    "\n",
    "Looks like this is the one we can actually use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d18e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "dataset_base_path = '/home/ebrahim/data/chest_xrays/MontgomerySet'\n",
    "dataset_imgs_path = os.path.join(dataset_base_path, 'CXR_png/')\n",
    "dataset_seg_path_left = os.path.join(dataset_base_path, 'ManualMask/leftMask')\n",
    "dataset_seg_path_right = os.path.join(dataset_base_path, 'ManualMask/rightMask')\n",
    "\n",
    "imgs = glob.glob(os.path.join(dataset_imgs_path, '*.png'))\n",
    "segs_left = glob.glob(os.path.join(dataset_seg_path_left, '*.png'))\n",
    "segs_right = glob.glob(os.path.join(dataset_seg_path_right, '*.png'))\n",
    "\n",
    "file_path_to_ID = lambda p : os.path.basename(p)[7:11]\n",
    "file_path_to_abnormality = lambda p : bool(int(os.path.basename(p)[12]))\n",
    "\n",
    "img_ids = list(map(file_path_to_ID,imgs));\n",
    "seg_ids_left = list(map(file_path_to_ID,segs_left));\n",
    "seg_ids_right = list(map(file_path_to_ID,segs_right));\n",
    "\n",
    "data = []\n",
    "for img in imgs:\n",
    "    img_id = file_path_to_ID(img)\n",
    "    seg_left = segs_left[seg_ids_left.index(img_id)]\n",
    "    seg_right = segs_right[seg_ids_right.index(img_id)]\n",
    "    tuberculosis = file_path_to_abnormality(img)\n",
    "    data.append({\n",
    "        'img' : img,\n",
    "        'seg_left' : seg_left,\n",
    "        'seg_right' : seg_right,\n",
    "        'tuberculosis' : tuberculosis\n",
    "\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9face75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4899a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = monai.data.utils.partition_dataset_classes(\n",
    "    data,\n",
    "    classes = list(map(lambda d : d['tuberculosis'], data)),\n",
    "    ratios = (8,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e919f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transforms\n",
    "from typing import Mapping, Hashable, List\n",
    "\n",
    "class MasksToOneHotD(monai.transforms.MapTransform):\n",
    "    def __init__(self, keys: monai.config.KeysCollection,\n",
    "                 keyList: List[Hashable], newKeyName: str) -> None:\n",
    "        super().__init__(keys)\n",
    "        self.keyList = keyList\n",
    "        self.newKeyName = newKeyName\n",
    "        assert(len(keyList)>0)\n",
    "\n",
    "    def __call__(self, data: Mapping[Hashable, np.ndarray]) -> Mapping[Hashable, np.ndarray]:\n",
    "        \n",
    "        # (if this were to be contributed, I'd have to pay attention to whether keys are in data)\n",
    "        # (also I'd want to raise more clear exceptions than these asserts)\n",
    "        \n",
    "        assert(all(key in self.keys for key in self.keyList))\n",
    "        assert(all(key in data.keys() for key in self.keyList))\n",
    "        assert(self.newKeyName not in data.keys())\n",
    "        \n",
    "        background_mask = (sum(data[key] for key in self.keyList)==0).astype('int8')\n",
    "        \n",
    "        # Assumes these were numpy arrays.\n",
    "        # If they were torch tensors we'd have to do \"torch.stack\" and use argument \"dim\" instead of \"axis\"\n",
    "        data[self.newKeyName] = np.stack(\n",
    "            [background_mask] + [data[key] for key in self.keyList],\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22032a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "\n",
    "transform_valid = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImageD(keys = ['img']),\n",
    "    monai.transforms.LoadImageD(keys = ['seg_left', 'seg_right'], dtype=\"int8\"),\n",
    "    monai.transforms.TransposeD(keys = ['img', 'seg_left', 'seg_right'], indices = (1,0)),\n",
    "    monai.transforms.AddChannelD(keys = ['img']),\n",
    "    MasksToOneHotD(\n",
    "        keys = ['seg_left', 'seg_right'],\n",
    "        keyList = ['seg_left', 'seg_right'],\n",
    "        newKeyName = 'seg'\n",
    "    ),\n",
    "    monai.transforms.DeleteItemsD(keys = ['seg_left', 'seg_right']),\n",
    "    monai.transforms.ResizeD(keys = ['img', 'seg'], spatial_size=(image_size,image_size)), # TODO: fix interp for seg!\n",
    "    monai.transforms.ToTensorD(keys = ['img', 'seg']),\n",
    "])\n",
    "\n",
    "transform_train = monai.transforms.Compose([\n",
    "    transform_valid,\n",
    "    monai.transforms.RandRotateD(keys = ['img', 'seg'],\n",
    "                                 range_x = np.pi/8, # TODO decrease ?\n",
    "                                 padding_mode=\"zeros\",\n",
    "                                 prob=1.,\n",
    "                                 mode = ['bilinear', 'nearest'])\n",
    "    # TODO add scaling\n",
    "    # randomly zero out parts of image?\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: switch back to CacheDataset once ready to start training\n",
    "\n",
    "dataset_train = monai.data.CacheDataset(data_train, transform_train)\n",
    "dataset_valid = monai.data.CacheDataset(data_valid, transform_valid)\n",
    "# dataset_train = monai.data.Dataset(data_train, transform_train)\n",
    "# dataset_valid = monai.data.Dataset(data_valid, transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408366ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_train[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a917619",
   "metadata": {},
   "source": [
    "# Previewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(data_item):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    im = data_item['img'].expand((3,)+data_item['img'].shape[1:])\n",
    "    im = im/im.max()\n",
    "    seg = data_item['seg'].float()\n",
    "    im[1,:,:] *= 1-0.3*seg[1,:,:]\n",
    "    im[2,:,:] *= 1-0.3*seg[2,:,:]\n",
    "    im = np.transpose(im,axes=(1,2,0))\n",
    "    plt.imshow(im, cmap='bone')\n",
    "    plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae5319",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "preview(random.choice(dataset_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74b25d",
   "metadata": {},
   "source": [
    "Note that some images have different original dimensions. Some are (4020, 4892) and some are (4892, 4020). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fa90b",
   "metadata": {},
   "source": [
    "# seg net\n",
    "\n",
    "Structure of U-Net is inspired by this paper: https://arxiv.org/abs/1703.08770\n",
    "\n",
    "But it's not exactly the same.\n",
    "\n",
    "And it looks like there's one giant deconvolution step at the end, instead of having a symmetric looking unet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cc865",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spatial_dims = 2;\n",
    "image_channels = 1;\n",
    "seg_channels = 3; # left lung, right lung, background\n",
    "seg_net_channel_seq = (8,8,16,32,64,64)\n",
    "stride_seq = (2,2,2,2,2) # I don't know why, but MONAI unet insists on this being one shorter than I expect,\n",
    "# and then it forces a stride of 1 at that last step.\n",
    "dropout_seg_net = 0.5\n",
    "num_res_units = 1\n",
    "\n",
    "seg_net = monai.networks.nets.UNet(\n",
    "    spatial_dims = spatial_dims,\n",
    "    in_channels = image_channels,\n",
    "    out_channels = seg_channels, \n",
    "    channels = seg_net_channel_seq,\n",
    "    strides = (2,2,2,2,2),\n",
    "    dropout = dropout_seg_net,\n",
    "    num_res_units = num_res_units\n",
    ")\n",
    "\n",
    "num_params = sum(p.numel() for p in seg_net.parameters())\n",
    "print(f\"seg_net has {num_params} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d510e8d5",
   "metadata": {},
   "source": [
    "# critic network\n",
    "\n",
    "Same shape as UNET but with the upsampling half lopped off and replaced by a fully connected layer.\n",
    "\n",
    "The output is a single logit-- needs sigmoid to make it a probability.\n",
    "\n",
    "It will be the probability that a given segmentation was from the training set.\n",
    "So the critic network is encouraged to output 1 on ground truth seg labels,\n",
    "and it's encouraged to output 0 on segmentations that were made by `seg_net`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f24e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_channels_and_strides = list(zip((seg_channels,) + seg_net_channel_seq,seg_net_channel_seq, stride_seq+(1,)))\n",
    "\n",
    "downsample_factor = np.array(critic_channels_and_strides)[:,2].prod()\n",
    "last_conv_layer_channels = np.array(critic_channels_and_strides)[-1,1]\n",
    "last_conv_layer_image_size = image_size // downsample_factor\n",
    "\n",
    "dropout_critic_net = 0.5 # TODO zero this?\n",
    "\n",
    "\n",
    "print(\"critic_net in_channels, out_channels, and strides for the convolutional part:\")\n",
    "print(critic_channels_and_strides)\n",
    "\n",
    "critic_net = torch.nn.Sequential(\n",
    "    *[\n",
    "        monai.networks.blocks.convolutions.ResidualUnit(\n",
    "            spatial_dims,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            strides = stride,\n",
    "            subunits = num_res_units,\n",
    "            dropout = dropout_critic_net,\n",
    "        )\n",
    "        for in_channels, out_channels, stride in critic_channels_and_strides\n",
    "    ],\n",
    "    monai.networks.layers.Flatten(),\n",
    "    torch.nn.Linear(last_conv_layer_image_size**2 * last_conv_layer_channels, 1) # output is logit; needs sigmoid\n",
    ")\n",
    "\n",
    "\n",
    "num_params = sum(p.numel() for p in critic_net.parameters())\n",
    "print(f\"critic_net has {num_params} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9f0e9",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = monai.losses.DiceLoss(\n",
    "    to_onehot_y = False, # the segs we pass in are already in one-hot form due to MasksToOneHotD defined above\n",
    "    softmax = True, # Note that our segmentation network is missing the softmax at the end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8553e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test drive\n",
    "data_item = dataset_train[42]\n",
    "seg_pred = seg_net(data_item['img'].unsqueeze(0)) # shape is (1,3,1024,1024), which is (B,N,H,W)\n",
    "\n",
    "dice_loss(\n",
    "    seg_net(data_item['img'].unsqueeze(0)), # input, one-hot\n",
    "    data_item['seg'].unsqueeze(0), # target, one-hot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss_logits = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45deaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test drive\n",
    "data_item = dataset_train[42]\n",
    "critic_pred = critic_net(data_item['seg'].unsqueeze(0))\n",
    "\n",
    "bce_loss_logits(critic_pred[0],torch.tensor([0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a401c0",
   "metadata": {},
   "source": [
    "# Previewing seg net outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddaac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_seg_net(data_item, figsize=(15,10), print_loss = True):\n",
    "    \n",
    "    seg_net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        im_device = data_item['img'].to(next(seg_net.parameters()).device.type)\n",
    "        seg_pred = seg_net(im_device.unsqueeze(0))[0].cpu()\n",
    "        _, max_indices = seg_pred.max(dim=0)\n",
    "        seg_pred_mask1 = (max_indices==1).type(torch.int8)\n",
    "        seg_pred_mask2 = (max_indices==2).type(torch.int8)\n",
    "\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "        im = data_item['img'].expand((3,)+data_item['img'].shape[1:])\n",
    "        im = im/im.max()\n",
    "\n",
    "        seg_true = data_item['seg'].float()\n",
    "        im_true = im.clone()\n",
    "        im_true[1,:,:] *= 1-0.3*seg_true[1,:,:]\n",
    "        im_true[2,:,:] *= 1-0.3*seg_true[2,:,:]\n",
    "        im_true = np.transpose(im_true,axes=(1,2,0))\n",
    "        ax1.imshow(im_true, cmap='bone')\n",
    "        ax1.set_title(\"true seg overlay\")\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.imshow(max_indices)\n",
    "        ax2.set_title(\"predicted seg\")\n",
    "        ax2.axis('off')\n",
    "\n",
    "        im_pred = im.clone()\n",
    "        im_pred[1,:,:] *= 1-0.6*seg_pred_mask1\n",
    "        im_pred[2,:,:] *= 1-0.6*seg_pred_mask2\n",
    "        im_pred = np.transpose(im_pred,axes=(1,2,0))\n",
    "        ax3.imshow(im_pred, cmap='bone')\n",
    "        ax3.set_title(\"predicted seg overlay\")\n",
    "        ax3.axis('off')\n",
    "\n",
    "        plt.show();\n",
    "\n",
    "        if print_loss:\n",
    "            loss = dice_loss(\n",
    "                seg_pred.unsqueeze(0),\n",
    "                data_item['seg'].unsqueeze(0),\n",
    "            )\n",
    "            print(f\"Dice loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c3c02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try seg_net on a random image.\n",
    "# preview_seg_net(random.choice(dataset_train));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348dc6fa",
   "metadata": {},
   "source": [
    "# Previewing critic net outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599560a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_critic_net(data_item):\n",
    "    critic_net.eval()\n",
    "    seg_net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        seg_net_device = next(seg_net.parameters()).device.type;\n",
    "        critic_net_device = next(critic_net.parameters()).device.type;\n",
    "        seg_pred = seg_net(data_item['img'].unsqueeze(0).to(seg_net_device)).cpu()\n",
    "        seg_true = data_item['seg'].float().unsqueeze(0)\n",
    "\n",
    "        # logit\n",
    "        critic_generated_seg = critic_net(seg_pred.to(critic_net_device)).cpu()\n",
    "        critic_real_seg = critic_net(seg_true.to(critic_net_device)).cpu()\n",
    "        \n",
    "        # probability\n",
    "        critic_generated_seg_p = critic_generated_seg.sigmoid().item()\n",
    "        critic_real_seg_p = critic_real_seg.sigmoid().item()\n",
    "\n",
    "        print(f\"Critic network confidence in the generated segmentation: {critic_generated_seg_p}\")\n",
    "        print(f\"Associated BCE loss: {bce_loss_logits(critic_generated_seg,torch.tensor([[0.]]))}\")\n",
    "        print(f\"Critic network confidence in the ground truth segmentation: {critic_real_seg_p}\")\n",
    "        print(f\"Associated BCE loss: {bce_loss_logits(critic_real_seg,torch.tensor([[1.]]))}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try seg_net on a random image.\n",
    "data_tiem  = random.choice(dataset_train)\n",
    "preview_seg_net(data_tiem);\n",
    "preview_critic_net(data_tiem);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d7c51",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d757d0a9",
   "metadata": {},
   "source": [
    "## Pretraining seg net alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57875d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seg_net.to('cuda')\n",
    "\n",
    "dataloader_train = monai.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = monai.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(seg_net.parameters(), learning_rate)\n",
    "\n",
    "max_epochs = 30\n",
    "training_losses = [] \n",
    "validation_losses = []\n",
    "\n",
    "for epoch_number in range(max_epochs):\n",
    "    \n",
    "    seg_net.train()\n",
    "    losses = []\n",
    "    for batch in dataloader_train:\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        true_segs = batch['seg'].to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_segs = seg_net(imgs)\n",
    "        loss = dice_loss(predicted_segs, true_segs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    training_loss = np.mean(losses)\n",
    "    \n",
    "    seg_net.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader_valid:\n",
    "            imgs = batch['img'].to('cuda')\n",
    "            true_segs = batch['seg'].to('cuda')\n",
    "            predicted_segs = seg_net(imgs)\n",
    "            loss = dice_loss(predicted_segs, true_segs)\n",
    "            losses.append(loss.item())\n",
    "        validation_loss = np.mean(losses)\n",
    "        \n",
    "    print(f\"Epoch {epoch_number+1}/{max_epochs}\\n\\ttraining loss: {training_loss}\\n\\tvalidation loss: {validation_loss}\")\n",
    "    training_losses.append(training_loss)\n",
    "    validation_losses.append(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de42fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del imgs, true_segs, predicted_segs, loss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c948d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preview_seg_net(random.choice(dataset_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_losses, label=\"training\")\n",
    "plt.plot(validation_losses, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mean dice loss')\n",
    "plt.title('seg net pretraining')\n",
    "plt.savefig('seg_net_pretraining_losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f822509",
   "metadata": {},
   "source": [
    "## Alternate training with critic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_training(network_to_train, network_to_not_train):\n",
    "    \"\"\"\n",
    "        Switch out of training one network and into training another\n",
    "    \"\"\"\n",
    "\n",
    "    for param in network_to_not_train.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in network_to_train.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    network_to_not_train.eval()\n",
    "    network_to_train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3646eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_net.to('cuda')\n",
    "critic_net.to('cuda')\n",
    "\n",
    "dataloader_train = monai.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = monai.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "lambda0 = 0.0001 # How much weight to give to critic score when training seg_net\n",
    "\n",
    "learning_rate_seg_net = 1e-3\n",
    "optimizer_seg_net = torch.optim.Adam(seg_net.parameters(), learning_rate_seg_net)\n",
    "training_losses_seg_net = [] \n",
    "validation_losses_seg_net = []\n",
    "\n",
    "learning_rate_critic_net = 1e-6\n",
    "optimizer_critic_net = torch.optim.SGD(critic_net.parameters(), learning_rate_critic_net)\n",
    "training_losses_critic_net = [] \n",
    "validation_losses_critic_net = []\n",
    "\n",
    "\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "for epoch_number in range(max_epochs):\n",
    "    \n",
    "    # --------------------------------\n",
    "    #          seg train\n",
    "    # --------------------------------\n",
    "    \n",
    "    swap_training(seg_net, critic_net)\n",
    "    losses = []\n",
    "    for batch in dataloader_train:\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        true_segs = batch['seg'].to('cuda')\n",
    "\n",
    "        optimizer_seg_net.zero_grad()\n",
    "        predicted_segs = seg_net(imgs)\n",
    "        critic_score = critic_net(predicted_segs)\n",
    "        loss = dice_loss(predicted_segs, true_segs) +\\\n",
    "               lambda0 * bce_loss_logits(critic_score,torch.ones_like(critic_score))\n",
    "        loss.backward()\n",
    "        optimizer_seg_net.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    training_loss = np.mean(losses)\n",
    "    print(f\"Epoch {epoch_number+1}/{max_epochs}\\n\\tseg training loss: {training_loss}\")\n",
    "    training_losses_seg_net.append([epoch_number, training_loss])\n",
    "    \n",
    "    \n",
    "    # --------------------------------\n",
    "    #          seg val\n",
    "    # --------------------------------\n",
    "    \n",
    "    if (epoch_number%5 == 0):\n",
    "        seg_net.eval()\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_valid:\n",
    "                imgs = batch['img'].to('cuda')\n",
    "                true_segs = batch['seg'].to('cuda')\n",
    "                predicted_segs = seg_net(imgs)\n",
    "                critic_score = critic_net(predicted_segs)\n",
    "                loss = dice_loss(predicted_segs, true_segs) +\\\n",
    "                       lambda0 * bce_loss_logits(critic_score,torch.ones_like(critic_score))\n",
    "                losses.append(loss.item())\n",
    "            validation_loss = np.mean(losses)\n",
    "        \n",
    "        print(f\"\\tseg validation loss: {validation_loss}\")\n",
    "        validation_losses_seg_net.append([epoch_number, validation_loss])\n",
    "    \n",
    "    # --- clean up ---\n",
    "    del imgs, true_segs, predicted_segs, critic_score, loss\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # --- Preview ---\n",
    "    if (epoch_number%5 == 0):\n",
    "        preview_seg_net(dataset_valid[17], figsize=(6,6), print_loss=False);\n",
    "    \n",
    "    \n",
    "    \n",
    "    # --------------------------------\n",
    "    #         critic train\n",
    "    # --------------------------------\n",
    "\n",
    "    \n",
    "    swap_training(critic_net, seg_net)\n",
    "    losses = []\n",
    "    for batch in dataloader_train:\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        true_segs = batch['seg'].float().to('cuda')\n",
    "        \n",
    "        optimizer_critic_net.zero_grad()\n",
    "        predicted_segs = seg_net(imgs)\n",
    "        critic_generated_segs = critic_net(predicted_segs)\n",
    "        critic_real_segs = critic_net(true_segs)\n",
    "        loss = bce_loss_logits(critic_generated_segs, torch.zeros_like(critic_generated_segs)) +\\\n",
    "               bce_loss_logits(critic_real_segs, torch.ones_like(critic_real_segs))\n",
    "        loss.backward()\n",
    "        optimizer_critic_net.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    training_loss = np.mean(losses)\n",
    "    print(f\"\\tcritic training loss: {training_loss}\")\n",
    "    training_losses_critic_net.append([epoch_number, training_loss])\n",
    "\n",
    "    # --------------------------------\n",
    "    #         critic val\n",
    "    # --------------------------------\n",
    "    \n",
    "    if (epoch_number%5 == 0):\n",
    "        critic_net.eval()\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_valid:\n",
    "                imgs = batch['img'].to('cuda')\n",
    "                true_segs = batch['seg'].float().to('cuda')\n",
    "                predicted_segs = seg_net(imgs)\n",
    "                critic_generated_segs = critic_net(predicted_segs)\n",
    "                critic_real_segs = critic_net(true_segs)\n",
    "                loss = bce_loss_logits(critic_generated_segs, torch.zeros_like(critic_generated_segs)) +\\\n",
    "                       bce_loss_logits(critic_real_segs, torch.ones_like(critic_real_segs))\n",
    "                losses.append(loss.item())\n",
    "            validation_loss = np.mean(losses)\n",
    "\n",
    "        print(f\"\\tcritic validation loss: {validation_loss}\")\n",
    "        validation_losses_critic_net.append([epoch_number, validation_loss])\n",
    "    \n",
    "    \n",
    "    del imgs, true_segs, predicted_segs, critic_generated_segs, critic_real_segs, loss\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against_epoch_numbers(epoch_value_pairs, label):\n",
    "    array = np.array(epoch_value_pairs)\n",
    "    plt.plot(array[:,0], array[:,1], label=label)\n",
    "\n",
    "plot_against_epoch_numbers(training_losses_seg_net, label=\"training\")\n",
    "plot_against_epoch_numbers(validation_losses_seg_net, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('seg net joint training')\n",
    "plt.savefig('seg_net_losses.png')\n",
    "plt.show()\n",
    "\n",
    "plot_against_epoch_numbers(training_losses_critic_net, label=\"training\")\n",
    "plot_against_epoch_numbers(validation_losses_critic_net, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('critic net joint training')\n",
    "plt.savefig('critic_net_losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1eeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT CELL; SAVE\n",
    "# torch.save(seg_net.state_dict(),'seg_net5.pth')\n",
    "# torch.save(critic_net.state_dict(),'critic_net5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32c133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CHECKPOINT CELL; LOAD\n",
    "# seg_net.load_state_dict(torch.load('seg_net5.pth'))\n",
    "# critic_net.load_state_dict(torch.load('critic_net5.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try both networks on a random validation image\n",
    "data_item_index  = random.choice(range(len(dataset_valid)))\n",
    "print(data_item_index)\n",
    "data_item = dataset_valid[data_item_index]\n",
    "with torch.no_grad():\n",
    "    preview_seg_net(data_item);\n",
    "    preview_critic_net(data_item);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to start with a decent pretrained seg net:\n",
    "# seg_net.load_state_dict(torch.load('seg_net3.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23d138",
   "metadata": {},
   "source": [
    "## Joint training approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2124890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_net.to('cuda')\n",
    "critic_net.to('cuda')\n",
    "\n",
    "def set_requires_grad(net, requires_grad : bool):\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "\n",
    "set_requires_grad(seg_net, True)\n",
    "set_requires_grad(critic_net, True)\n",
    "\n",
    "dataloader_train = monai.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_valid = monai.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "lambda0 = 0.05 # How much weight to give to critic score when training seg_net\n",
    "\n",
    "learning_rate_seg_net = 1e-3\n",
    "optimizer_seg_net = torch.optim.Adam(seg_net.parameters(), learning_rate_seg_net)\n",
    "training_losses_seg_net = [] \n",
    "validation_losses_seg_net = []\n",
    "\n",
    "learning_rate_critic_net = 1e-3\n",
    "optimizer_critic_net = torch.optim.SGD(critic_net.parameters(), learning_rate_critic_net)\n",
    "training_losses_critic_net = [] \n",
    "validation_losses_critic_net = []\n",
    "\n",
    "\n",
    "\n",
    "max_epochs = 1000\n",
    "\n",
    "for epoch_number in range(max_epochs):\n",
    "    \n",
    "    # --------------------------------\n",
    "    #          train both\n",
    "    # --------------------------------\n",
    "    \n",
    "    seg_net.train()\n",
    "    critic_net.train()\n",
    "    seg_losses = []\n",
    "    critic_losses = []\n",
    "    for batch in dataloader_train:\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        true_segs = batch['seg'].float().to('cuda')\n",
    "        \n",
    "        optimizer_seg_net.zero_grad()\n",
    "        set_requires_grad(seg_net, True)\n",
    "        \n",
    "        predicted_segs = seg_net(imgs)\n",
    "        critic_generated_segs = critic_net(predicted_segs)\n",
    "        seg_loss = dice_loss(predicted_segs, true_segs) +\\\n",
    "                   lambda0 * bce_loss_logits(critic_generated_segs,torch.ones_like(critic_generated_segs.detach()))\n",
    "        \n",
    "        seg_loss.backward(retain_graph=True)\n",
    "        set_requires_grad(seg_net, False)\n",
    "        optimizer_critic_net.zero_grad()\n",
    "        \n",
    "        critic_real_segs = critic_net(true_segs)\n",
    "        critic_generated_segs_loss = bce_loss_logits(\n",
    "            critic_generated_segs,\n",
    "            torch.zeros_like(critic_generated_segs)\n",
    "        )\n",
    "        critic_real_segs_loss = bce_loss_logits(\n",
    "            critic_real_segs,\n",
    "            torch.ones_like(critic_real_segs)\n",
    "        )\n",
    "        critic_loss = critic_generated_segs_loss + critic_real_segs_loss\n",
    "        \n",
    "        critic_loss.backward()\n",
    "\n",
    "        optimizer_seg_net.step()\n",
    "        optimizer_critic_net.step()\n",
    "\n",
    "        seg_losses.append(seg_loss.item())\n",
    "        critic_losses.append(critic_loss.item())\n",
    "    \n",
    "    seg_training_loss = np.mean(seg_losses)\n",
    "    critic_training_loss = np.mean(critic_losses)\n",
    "    print(f\"Epoch {epoch_number+1}/{max_epochs}\")\n",
    "    print(f\"\\tseg training loss: {seg_training_loss}\")\n",
    "    print(f\"\\tcrt training loss: {critic_training_loss}\")\n",
    "    training_losses_seg_net.append([epoch_number, seg_training_loss])\n",
    "    training_losses_critic_net.append([epoch_number, critic_training_loss])\n",
    "    \n",
    "    del imgs, true_segs, predicted_segs, critic_generated_segs, seg_loss,\\\n",
    "        critic_real_segs, critic_real_segs_loss, critic_generated_segs_loss, critic_loss\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # Switch to evaluation mode for validation\n",
    "    seg_net.eval()\n",
    "    critic_net.eval()\n",
    "    \n",
    "    # --------------------------------\n",
    "    #          seg val\n",
    "    # --------------------------------\n",
    "    \n",
    "    if (epoch_number%5 == 0):\n",
    "        \n",
    "        losses = []\n",
    "        losses_dice_only = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_valid:\n",
    "                imgs = batch['img'].to('cuda')\n",
    "                true_segs = batch['seg'].to('cuda')\n",
    "                predicted_segs = seg_net(imgs)\n",
    "                critic_score = critic_net(predicted_segs)\n",
    "                seg_similarity_loss = dice_loss(predicted_segs, true_segs)\n",
    "                loss = seg_similarity_loss +\\\n",
    "                       lambda0 * bce_loss_logits(critic_score,torch.ones_like(critic_score))\n",
    "                losses.append(loss.item())\n",
    "                losses_dice_only.append(seg_similarity_loss.item())\n",
    "            validation_loss = np.mean(losses)\n",
    "            validation_loss_dice_only = np.mean(losses_dice_only)\n",
    "        \n",
    "        print(f\"\\tseg validation loss: {validation_loss}; dice only: {validation_loss_dice_only}\")\n",
    "        validation_losses_seg_net.append([epoch_number, validation_loss])\n",
    "    \n",
    "        # --- clean up ---\n",
    "        del imgs, true_segs, predicted_segs, critic_score, loss, seg_similarity_loss\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "\n",
    "    # --------------------------------\n",
    "    #         critic val\n",
    "    # --------------------------------\n",
    "    \n",
    "    if (epoch_number%5 == 0):\n",
    "        critic_net.eval()\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_valid:\n",
    "                imgs = batch['img'].to('cuda')\n",
    "                true_segs = batch['seg'].float().to('cuda')\n",
    "                predicted_segs = seg_net(imgs)\n",
    "                critic_generated_segs = critic_net(predicted_segs)\n",
    "                critic_real_segs = critic_net(true_segs)\n",
    "                loss = bce_loss_logits(critic_generated_segs, torch.zeros_like(critic_generated_segs)) +\\\n",
    "                       bce_loss_logits(critic_real_segs, torch.ones_like(critic_real_segs))\n",
    "                losses.append(loss.item())\n",
    "            validation_loss = np.mean(losses)\n",
    "\n",
    "        print(f\"\\tcritic validation loss: {validation_loss}\")\n",
    "        validation_losses_critic_net.append([epoch_number, validation_loss])\n",
    "\n",
    "    \n",
    "        del imgs, true_segs, predicted_segs, critic_generated_segs, critic_real_segs, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # --- Preview ---\n",
    "    if (epoch_number%5 == 0):\n",
    "        preview_seg_net(dataset_valid[18], figsize=(6,6), print_loss=False);\n",
    "        \n",
    "    # STOP if the critic network has gotten too good; this is a failure mode of adversarial training\n",
    "    if critic_training_loss < 0.01:\n",
    "        optimizer_critic_net = torch.optim.SGD(critic_net.parameters(), 1e-6)\n",
    "    elif critic_training_loss < 0.1:\n",
    "        optimizer_critic_net = torch.optim.SGD(critic_net.parameters(), 1e-5)\n",
    "    elif critic_training_loss < 0.3:\n",
    "        optimizer_critic_net = torch.optim.SGD(critic_net.parameters(), 1e-4)\n",
    "    else:\n",
    "        optimizer_critic_net = torch.optim.SGD(critic_net.parameters(), 1e-3)\n",
    "    \n",
    "#         print(\"\"\"Critic network training loss is low; stopping.\n",
    "#               You could continue with different learning rates and/or thresholds\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT CELL; SAVE\n",
    "run_id = '0007'\n",
    "# torch.save(seg_net.state_dict(),f'seg_net{run_id}.pth')\n",
    "# torch.save(critic_net.state_dict(),f'critic_net{run_id}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT CELL; LOAD\n",
    "# seg_net.load_state_dict(torch.load(f'seg_net{run_id}.pth'))\n",
    "# critic_net.load_state_dict(torch.load(f'critic_net{run_id}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try both networks on a random validation image\n",
    "data_item_index  = random.choice(range(len(dataset_valid)))\n",
    "data_item_index=18\n",
    "print(data_item_index)\n",
    "data_item = dataset_valid[data_item_index]\n",
    "with torch.no_grad():\n",
    "    preview_seg_net(data_item);\n",
    "    preview_critic_net(data_item);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against_epoch_numbers(epoch_value_pairs, label):\n",
    "    array = np.array(epoch_value_pairs)\n",
    "    plt.plot(array[:,0], array[:,1], label=label)\n",
    "\n",
    "plot_against_epoch_numbers(training_losses_seg_net, label=\"training\")\n",
    "plot_against_epoch_numbers(validation_losses_seg_net, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('seg net joint training')\n",
    "plt.savefig(f'seg_net_losses{run_id}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_against_epoch_numbers(training_losses_critic_net, label=\"training\")\n",
    "plot_against_epoch_numbers(validation_losses_critic_net, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('critic net joint training')\n",
    "plt.savefig(f'critic_net_losses{run_id}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d01e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
