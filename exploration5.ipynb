{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9caddba5",
   "metadata": {},
   "source": [
    "Similar to exploration2, but this time including an addition dataset (Shenzhen) and not separating between right and left lung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f933a5",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "## Some publicly available datasets\n",
    "\n",
    "- [JSRT](https://www.ajronline.org/doi/pdf/10.2214/ajr.174.1.1740071)\n",
    "\t- 247 chest X-rays, 154 have lung nodules. Has lung and heart seg.\n",
    "\t- [Get here](http://db.jsrt.or.jp/eng.php) (register at bottom of page)\n",
    "- [Montgomery and Shenzhen](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/)\n",
    "\t- Montgomery contains 138 chest X-rays, 80 healthy, 58 tuberculosis. Has lung seg.\n",
    "\t- Shenzhen contains 662 chest X-rays, 326 healthy, 336 tuberculosis. Has lung seg.\n",
    "\t- [Get both here](https://openi.nlm.nih.gov/faq?it=xg#collection). Look for \"tuberculosis collection\"\n",
    "\n",
    "That’s 1047 images with lung segmentation label. There are larger datasets that have no segmentation label:\n",
    "\n",
    "- [NIH ChestX-ray8](https://arxiv.org/abs/1705.02315)\n",
    "\t- 108,948 CXRs of 32,717 patients with eight text-mined disease labels\n",
    "\t- [this might be a way to download](https://nihcc.app.box.com/v/ChestXray-NIHCC)\n",
    "- [NLST](https://www.nejm.org/doi/10.1056/NEJMoa1102873)\n",
    "\t- There's [this link](https://cdas.cancer.gov/publications/320/), which eventually leads [here](https://cdas.cancer.gov/datasets/nlst/), but I don't see any actual CXR images being made available.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8e455",
   "metadata": {},
   "source": [
    "### JSRT\n",
    "\n",
    "See [this guide](JSRT_UsersGuide.pdf) to the data for details.\n",
    "\n",
    "- `JPCLN***.IMG` for chest lung nodule images, and `JPCNN***.IMG` for non-nodule images. These are important classes to keep in mind for the purpose of proportional train/val/test split.\n",
    "-  coordinates of the upper left of the image are `(0,0)`\n",
    "- Image type: 16-bit Unsigned\n",
    "- Width: 2048 pixels\n",
    "- Height: 2048 pixels\n",
    "- Offset to First Image: 0 bytes\n",
    "- Gap Between Images: 0 bytes\n",
    "\n",
    "You can load the images using [ImageJ](https://imagej.nih.gov/ij/).\n",
    "Just import as \"RAW\" and put in the settings specified by the JSRT guide.\n",
    "\n",
    "Hmm, stuck on this for now... also where are the segmentations? When I load RAW data into Image J I only see an xray image, and I see no reference to segmentation in the JSRT guide. The JSRT download page doesn't say anything about segmentation labels either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f0734",
   "metadata": {},
   "source": [
    "### Shenzhen\n",
    "\n",
    "[The readme](NLM-ChinaCXRSet-ReadMe.pdf).\n",
    "\n",
    "- 336 cases with manifestation of tuberculosis, and \n",
    "- 326 normal cases.\n",
    "\n",
    "- Format: PNG\n",
    "- Image size varies for each X-ray. It is approximately 3K x 3K.\n",
    "\n",
    "- Image file names are coded as `CHNCXR_#####_0/1.png`, where ‘0’ represents the normal and ‘1’\n",
    "represents the abnormal lung. \n",
    "\n",
    "Segmentation can be obtained separately [here](https://www.kaggle.com/yoctoman/shcxr-lung-mask), and it was done manually by: \"students and teachers of Computer Engineering Department, Faculty of Informatics and Computer Engineering, National Technical University of Ukraine \"Igor Sikorsky Kyiv Polytechnic Institute\", Kyiv, Ukraine.\" So, not necessarily medical experts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6d7e7",
   "metadata": {},
   "source": [
    "### Montgomery\n",
    "\n",
    "[The readme](NLM-MontgomeryCXRSet-ReadMe.pdf).\n",
    "\n",
    "- 58 cases\twith\tmanifestation\tof\ttuberculosis,\tand\t 80 normal\tcases.\n",
    "- Image\t file\t names\tare\t coded\tas\t`MCUCXR_#####_0/1.png`, where\t‘0’\t represents\t the\t normal\tand\t‘1’ represents\tthe\tabnormal\tlung. These are important classes to keep in mind for the purpose of proportional train/val/test split.\n",
    "\n",
    "---\n",
    "\n",
    "- Format:\tPNG\n",
    "- Matrix\tsize\tis\t4020\tx\t4892,\tor\t4892\tx\t4020.\n",
    "- The\tpixel\tspacing\tin\tvertical\tand\thorizontal\tdirections\tis\t0.0875\tmm.\t\n",
    "- Number\tof\tgray\tlevels\tis\t12 bits.\n",
    "\n",
    "---\n",
    "\n",
    "Segmentation:\n",
    "> We\tmanually\tgenerated\tthe\t“gold\tstandard” segmentations\tfor\tthe\tchest\tX-ray\tunder\tthe\tsupervision\tof a\tradiologist.\tWe\tused\tthe\tfollowing\tconventions\tfor outlining\tthe\tlung\tboundaries:\tBoth\tposterior\tand\tanterior\tribs\tare\treadily\tvisible\tin\tthe\tCXRs;\tthe\tpart\tof\tthe\tlung\tbehind\tthe\theart\tis\texcluded.\tWe\tfollow\tanatomical\t landmarks\t such\t as\t the\t boundary\t of\t the\t heart,\t aortic\t arc/line,\t and\t pericardium\t line;\t and\tsharp\tcostophrenic\tangle\tthat\tfollow\tthe\tdiaphragm\tboundary. We\tdraw\tan\tinferred\tboundary\twhen\tthe\tpathology\tis\tsevere\tand\taffects\tthe\tmorphological\tappearance\tof\tthe\tlungs. The\tlung\tboundaries\t(left\tand\tright)\tare\tin\tbinary\timage\tformat\tand\thave\tthe\tsame\tfile\tname\tas\tchest\tXrays\t( e.g.\t`…/left/MCUCXR_#####_0/1.png` or\t`…/right/MCUCXR_#####_0/1.png`). \n",
    "\n",
    "### Data used here\n",
    "\n",
    "We will use Montgomery and Shenzhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d18e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "data_base_path = '/home/ebrahim/data/chest_xrays'\n",
    "\n",
    "montgomery_imgs_path = os.path.join(data_base_path, 'MontgomerySet/CXR_png')\n",
    "montgomery_segs_path_left = os.path.join(data_base_path, 'MontgomerySet/ManualMask/leftMask')\n",
    "montgomery_segs_path_right = os.path.join(data_base_path, 'MontgomerySet/ManualMask/rightMask')\n",
    "\n",
    "shenzhen_imgs_path = os.path.join(data_base_path, 'ChinaSet_AllFiles/CXR')\n",
    "shenzhen_segs_path = os.path.join(data_base_path, 'ChinaSet_AllFiles/CXR_segs')\n",
    "\n",
    "montgomery_imgs = glob.glob(os.path.join(montgomery_imgs_path, '*.png'))\n",
    "montgomery_segs_left = glob.glob(os.path.join(montgomery_segs_path_left, '*.png'))\n",
    "montgomery_segs_right = glob.glob(os.path.join(montgomery_segs_path_right, '*.png'))\n",
    "\n",
    "shenzhen_imgs = glob.glob(os.path.join(shenzhen_imgs_path, '*.png'))\n",
    "shenzhen_segs = glob.glob(os.path.join(shenzhen_segs_path, '*.png'))\n",
    "\n",
    "# These happen to work the same way for both montgomery and shenzhen datasets\n",
    "file_path_to_ID = lambda p : os.path.basename(p)[7:11]\n",
    "file_path_to_abnormality = lambda p : bool(int(os.path.basename(p)[12]))\n",
    "\n",
    "montgomery_img_ids = list(map(file_path_to_ID,montgomery_imgs))\n",
    "montgomery_seg_ids_left = list(map(file_path_to_ID,montgomery_segs_left))\n",
    "montgomery_seg_ids_right = list(map(file_path_to_ID,montgomery_segs_right))\n",
    "\n",
    "shenzhen_img_ids = list(map(file_path_to_ID,shenzhen_imgs))\n",
    "shenzhen_seg_ids = list(map(file_path_to_ID,shenzhen_segs))\n",
    "\n",
    "# See \"look over data to sanity check\" section below.\n",
    "# I used that cell to actually look over the segmentations by hand, because some of them were bad\n",
    "# I excluded segmentations that ignored the heart boundary, since that is not consistent with montgomery set segs\n",
    "# I excluded segmentations that were clearly impossible given how the diaphram can be arranged\n",
    "shenzhen_excluded_ids = [\n",
    "    '0043', '0242', '0439', '0518', '0506', '0635', '0337',\n",
    "    '0603', '0455', '0254', '0610', '0028', '0511', '0059',\n",
    "    '0031', '0297', '0032', '0327', '0569', '0030', '0178',\n",
    "    '0295', '0298', '0003', '0022', '0020', '0098', '0033', \n",
    "    '0250', '0423', '0066', '0464', '0381', '0289', '0253',\n",
    "    '0338', '0076', '0621', '0243', '0016', '0241', '0339',\n",
    "    '0324', '0007', '0660', '0285', '0294', '0286', '0281', \n",
    "    '0047', '0527', '0013', '0002', '0046', '0370', '0293', \n",
    "    '0372', '0361', '0290', '0474', '0513', '0090', \n",
    "]\n",
    "\n",
    "data = []\n",
    "for img in montgomery_imgs:\n",
    "    img_id = file_path_to_ID(img)\n",
    "    seg_left = montgomery_segs_left[montgomery_seg_ids_left.index(img_id)]\n",
    "    seg_right = montgomery_segs_right[montgomery_seg_ids_right.index(img_id)]\n",
    "    tuberculosis = file_path_to_abnormality(img)\n",
    "    data.append({\n",
    "        'img' : img,\n",
    "        'mo_seg_left' : seg_left, # mo for montgomery\n",
    "        'mo_seg_right' : seg_right,\n",
    "        'tuberculosis' : tuberculosis,\n",
    "        'id' : 'montgomery:'+img_id,\n",
    "        'source' : \"montgomery\"\n",
    "    })\n",
    "skipped_no_seg = 0\n",
    "skipped_bad = 0\n",
    "for img in shenzhen_imgs:\n",
    "    img_id = file_path_to_ID(img)\n",
    "    if img_id not in shenzhen_seg_ids:\n",
    "        skipped_no_seg += 1\n",
    "        continue\n",
    "    if img_id in shenzhen_excluded_ids:\n",
    "        skipped_bad += 1\n",
    "        continue\n",
    "    seg = shenzhen_segs[shenzhen_seg_ids.index(img_id)]\n",
    "    tuberculosis = file_path_to_abnormality(img)\n",
    "    data.append({\n",
    "        'img' : img,\n",
    "        'sh_seg' : seg, # sh for shenzhen\n",
    "        'tuberculosis' : tuberculosis,\n",
    "        'id' : 'shenzhen:'+img_id,\n",
    "        'source' : \"shenzhen\"\n",
    "    })\n",
    "if skipped_no_seg>0:\n",
    "    print(f\"{skipped_no_seg} of the shenzhen images do not have an associated segmentation, and they were skipped.\")\n",
    "    print(f\"{skipped_bad} of the shenzhen images were marked for exclusion due to questionable segmentation.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9face75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from util import UnionMasksD, rgb_to_grayscale, list_data_collate_no_meta\n",
    "from segmentation_post_processing import SegmentationPostProcessing\n",
    "\n",
    "monai.utils.misc.set_determinism(seed=9274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4899a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = monai.data.utils.partition_dataset_classes(\n",
    "    data,\n",
    "    classes = list(map(lambda d : str(d['tuberculosis'])+d['source'], data)),\n",
    "    ratios = (8,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22032a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "\n",
    "keys_to_delete = ['mo_seg_left', 'mo_seg_right', 'sh_seg']\n",
    "keys_to_delete += [k+\"_meta_dict\" for k in keys_to_delete] + [k+\"_transforms\" for k in keys_to_delete]\n",
    "\n",
    "transform_valid = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImageD(reader='itkreader',keys = ['img']), # A few shenzhen images get mysteriously value-inverted with readers other than itkreader\n",
    "    monai.transforms.LambdaD(keys=['img'], func = rgb_to_grayscale), # A few of the shenzhen imgs are randomly RGB encoded rather than grayscale colormap\n",
    "    monai.transforms.LoadImageD(keys = ['mo_seg_left', 'mo_seg_right', 'sh_seg'], dtype=\"int8\", allow_missing_keys=True),\n",
    "    monai.transforms.TransposeD(keys = ['img', 'mo_seg_left', 'mo_seg_right', 'sh_seg'], indices = (1,0), allow_missing_keys=True),\n",
    "    monai.transforms.AddChannelD(keys = ['img']),\n",
    "    UnionMasksD(keys = ['mo_seg_left', 'mo_seg_right'], keyList=['mo_seg_left', 'mo_seg_right'], newKeyName='seg'),\n",
    "    UnionMasksD(keys = ['sh_seg',], keyList=['sh_seg'], newKeyName='seg'), # using for one-hot conversion, not \"union\"\n",
    "    monai.transforms.DeleteItemsD(keys = keys_to_delete),\n",
    "    monai.transforms.ResizeD(\n",
    "        keys = ['img', 'seg'],\n",
    "        spatial_size=(image_size,image_size),\n",
    "        mode = ['bilinear', 'nearest']\n",
    "    ),\n",
    "    monai.transforms.ToTensorD(keys = ['img', 'seg']),\n",
    "])\n",
    "\n",
    "transform_train = monai.transforms.Compose([\n",
    "    transform_valid,\n",
    "    monai.transforms.RandCoarseDropoutd(\n",
    "        keys = ['img'],\n",
    "        holes = 1,\n",
    "        max_holes=3,\n",
    "        spatial_size=image_size//32,\n",
    "        max_spatial_size=image_size//4,\n",
    "        prob=0.5,\n",
    "        fill_value=255\n",
    "    ),\n",
    "    monai.transforms.RandCoarseDropoutd(\n",
    "        keys = ['img'],\n",
    "        holes = 1,\n",
    "        max_holes=3,\n",
    "        spatial_size=image_size//32,\n",
    "        max_spatial_size=image_size//4,\n",
    "        prob=0.5,\n",
    "        fill_value=0\n",
    "    ),\n",
    "    monai.transforms.RandZoomD(\n",
    "        keys = ['img', 'seg'],\n",
    "        mode = ['bilinear', 'nearest'],\n",
    "        prob=1.,\n",
    "        padding_mode=\"constant\",\n",
    "        min_zoom = 0.7,\n",
    "        max_zoom=1.3,\n",
    "    ),\n",
    "    monai.transforms.RandRotateD(\n",
    "        keys = ['img', 'seg'],\n",
    "        mode = ['bilinear', 'nearest'],\n",
    "        prob=1.,\n",
    "        range_x = np.pi/8,\n",
    "        padding_mode=\"zeros\",\n",
    "    ),\n",
    "    monai.transforms.RandGaussianSmoothD(\n",
    "        keys = ['img'],\n",
    "        prob = 0.4\n",
    "    ),\n",
    "    monai.transforms.RandAdjustContrastD(\n",
    "        keys = ['img'],\n",
    "        prob=0.4,\n",
    "    ),\n",
    "    monai.transforms.ToNumpyD(keys=['img']),\n",
    "    monai.transforms.RandHistogramShiftD(\n",
    "        keys = ['img'],\n",
    "        prob=0.0,\n",
    "    ),\n",
    "    monai.transforms.ToTensorD(keys=['img', 'seg']),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91631281",
   "metadata": {},
   "source": [
    "# Look over data to sanity check\n",
    "\n",
    "There are some problematic segmenations in the Shenzhen set, e.g. some include the heart, some are very messy\n",
    "\n",
    "Catch them here and add fix them to exclusion list above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adaac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization cell for data preview procedure -- run this once\n",
    "\n",
    "binary_mask = lambda x : (x!=0).astype('float')\n",
    "bdry = lambda s : binary_mask((np.abs(np.diff(s, axis=0, prepend=0)) + np.abs(np.diff(s, axis=1, prepend=0)))!=0)\n",
    "bdry_thick = lambda s : binary_mask(bdry(bdry(s)) + bdry(s))\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2469c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Iteration cell -- run this several times till you have run through all the data or you are satisfied\n",
    "num_rows = 2\n",
    "fig, axs = plt.subplots(num_rows,5,figsize=(20,5*num_rows))\n",
    "for ax in axs.reshape(-1):\n",
    "    if i>=len(data): break\n",
    "\n",
    "    d = data[i]\n",
    "    d = transform_valid(d)\n",
    "    \n",
    "    im = d['img'].expand((3,)+d['img'].shape[1:])\n",
    "    im = im/im.max()\n",
    "    seg = d['seg'].float()\n",
    "    seg_bdry = bdry_thick(seg[1])\n",
    "    im[0,seg_bdry==1.] = 1 # R\n",
    "    im[1,seg_bdry==1.] = 0 # G\n",
    "    im[2,seg_bdry==1.] = 0 # B\n",
    "    im = np.transpose(im,axes=(1,2,0))\n",
    "    ax.imshow(im, cmap='bone')\n",
    "    \n",
    "    ax.set_title(f\"i={i}, id={d['id']}\")\n",
    "    \n",
    "    \n",
    "    i+=1\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a917619",
   "metadata": {},
   "source": [
    "# Previewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(data_item, show_bdry = False):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    im = data_item['img'].expand((3,)+data_item['img'].shape[1:])\n",
    "    im = im/im.max()\n",
    "    seg = data_item['seg'].float()\n",
    "    im[1,:,:] *= 1-0.3*seg[1,:,:]\n",
    "    if show_bdry:\n",
    "        seg_bdry = bdry(seg[1])\n",
    "        mask = (seg_bdry == 1.)\n",
    "        im[0,mask], im[1,mask], im[2,mask] = 1,0,0 # R, G, B\n",
    "    im = np.transpose(im,axes=(1,2,0))\n",
    "    plt.imshow(im, cmap='bone')\n",
    "    plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = monai.data.CacheDataset(data_train, transform_train)\n",
    "dataset_valid = monai.data.CacheDataset(data_valid, transform_valid)\n",
    "# dataset_train = monai.data.Dataset(data_train, transform_train)\n",
    "# dataset_valid = monai.data.Dataset(data_valid, transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae5319",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.choice(range(len(dataset_train)))\n",
    "d = dataset_train[i]\n",
    "preview(d, show_bdry=True)\n",
    "print(d['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fa90b",
   "metadata": {},
   "source": [
    "# seg net\n",
    "\n",
    "Structure of U-Net is inspired by this paper: https://arxiv.org/abs/1703.08770\n",
    "\n",
    "But it's not exactly the same. In the paper there's one giant deconvolution step at the end, instead of having a symmetric looking unet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cc865",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spatial_dims = 2;\n",
    "image_channels = 1;\n",
    "seg_channels = 2; # lung, background\n",
    "seg_net_channel_seq = (8,16,32,32,32,64,64,64)\n",
    "stride_seq = (2,2,2,2,1,2,1) # I don't know why, but MONAI unet insists on this being one shorter than I expect,\n",
    "# and then it forces a stride of 1 at that last step.\n",
    "dropout_seg_net = 0.5\n",
    "num_res_units = 2\n",
    "\n",
    "seg_net = monai.networks.nets.UNet(\n",
    "    spatial_dims = spatial_dims,\n",
    "    in_channels = image_channels,\n",
    "    out_channels = seg_channels, \n",
    "    channels = seg_net_channel_seq,\n",
    "    strides = stride_seq,\n",
    "    dropout = dropout_seg_net,\n",
    "    num_res_units = num_res_units\n",
    ")\n",
    "\n",
    "num_params = sum(p.numel() for p in seg_net.parameters())\n",
    "print(f\"seg_net has {num_params} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9f0e9",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = monai.losses.DiceLoss(\n",
    "    to_onehot_y = False, # the segs we pass in are already in one-hot form\n",
    "    softmax = True, # Note that our segmentation network is missing the softmax at the end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8553e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test drive\n",
    "data_item = dataset_train[42]\n",
    "seg_pred = seg_net(data_item['img'].unsqueeze(0)) # shape is (1,3,1024,1024), which is (B,N,H,W)\n",
    "\n",
    "dice_loss(\n",
    "    seg_net(data_item['img'].unsqueeze(0)), # input, one-hot\n",
    "    data_item['seg'].unsqueeze(0), # target, one-hot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a401c0",
   "metadata": {},
   "source": [
    "# Previewing seg net outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddaac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_seg_net(data_item, figsize=(15,10), print_loss = True, show_heatmap = False, show_bdry=False, show_post_processing=0):\n",
    "    \"\"\"\n",
    "    Preview seg net prediciton\n",
    "    \n",
    "    Args:\n",
    "        data_item: A data item to input into seg_net.\n",
    "        figsize: figure size to be used at each matplotlib plotting call\n",
    "        print_loss: show Dice loss\n",
    "        show_heatmap: whether to show class probability image\n",
    "        show_bdry: whether to draw the boundry\n",
    "        show_post_processing: 0 to not show it,\n",
    "            1 to show post processed result,\n",
    "            2 to show post processed result and intermediate steps\n",
    "    \"\"\"\n",
    "    \n",
    "    seg_net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        im_device = data_item['img'].to(next(seg_net.parameters()).device.type)\n",
    "        seg_pred = seg_net(im_device.unsqueeze(0))[0].cpu()\n",
    "        _, max_indices = seg_pred.max(dim=0)\n",
    "        seg_pred_mask = (max_indices==1).type(torch.uint8)\n",
    "\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "        im = data_item['img'].expand((3,)+data_item['img'].shape[1:])\n",
    "        im = im/im.max()\n",
    "\n",
    "        seg_true = data_item['seg'].float()\n",
    "        im_true = im.clone()\n",
    "        im_true[1,:,:] *= 1-0.4*seg_true[1,:,:]\n",
    "        if show_bdry:\n",
    "            seg_true_bdry = bdry(seg_true[1])\n",
    "            mask = (seg_true_bdry == 1.)\n",
    "            im_true[0,mask], im_true[1,mask], im_true[2,mask] = 1,0,0 # R, G, B\n",
    "        im_true = np.transpose(im_true,axes=(1,2,0))\n",
    "        ax1.imshow(im_true, cmap='bone')\n",
    "        ax1.set_title(\"true seg overlay\")\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.imshow(max_indices)\n",
    "        ax2.set_title(\"predicted seg\")\n",
    "        ax2.axis('off')\n",
    "\n",
    "        im_pred = im.clone()\n",
    "        im_pred[1,:,:] *= 1-0.4*seg_pred_mask\n",
    "        if show_bdry:\n",
    "            seg_pred_bdry = bdry(seg_pred_mask)\n",
    "            mask = (seg_pred_bdry == 1.)\n",
    "            im_pred[0,mask], im_pred[1,mask], im_pred[2,mask] = 1,0,0 # R, G, B\n",
    "        im_pred = np.transpose(im_pred,axes=(1,2,0))\n",
    "        ax3.imshow(im_pred, cmap='bone')\n",
    "        ax3.set_title(\"predicted seg overlay\")\n",
    "        ax3.axis('off')\n",
    "\n",
    "        plt.show();\n",
    "        \n",
    "        if show_heatmap:\n",
    "            f, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "            ax1.imshow(seg_pred.softmax(dim=0)[1])\n",
    "            ax1.axis('off')\n",
    "            print(\"predicted seg class probability maps:\")\n",
    "            plt.show()\n",
    "        \n",
    "        if show_post_processing!=0:\n",
    "            plt.figure(figsize = figsize)\n",
    "            seg_post_process = SegmentationPostProcessing()\n",
    "            seg_pred_processed = seg_post_process(seg_pred_mask)\n",
    "            im_pred = im.clone()\n",
    "            im_pred[1,:,:] *= 1-0.4*(seg_pred_processed==1)\n",
    "            im_pred[0,:,:] *= 1-0.4*(seg_pred_processed==2)\n",
    "            if show_bdry:\n",
    "                seg_pred_bdry1 = bdry(seg_pred_processed==1)\n",
    "                seg_pred_bdry2 = bdry(seg_pred_processed==2)\n",
    "                mask1 = (seg_pred_bdry1 == 1.)\n",
    "                mask2 = (seg_pred_bdry2 == 1.)\n",
    "                im_pred[0,mask1], im_pred[1,mask1], im_pred[2,mask1] = 1,0,0 # R, G, B\n",
    "                im_pred[0,mask2], im_pred[1,mask2], im_pred[2,mask2] = 0,1,0 # R, G, B\n",
    "            im_pred = np.transpose(im_pred,axes=(1,2,0))\n",
    "            plt.imshow(im_pred, cmap='bone')\n",
    "            plt.title(\"post-processed segmentation overlay\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            if show_post_processing>1:\n",
    "                seg_post_process.preview_intermediate_steps()\n",
    "\n",
    "        if print_loss:\n",
    "            loss = dice_loss(\n",
    "                seg_pred.unsqueeze(0),\n",
    "                data_item['seg'].unsqueeze(0),\n",
    "            )\n",
    "            print(f\"Dice loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c3c02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try seg_net on a random image.\n",
    "preview_seg_net(random.choice(dataset_train), show_bdry=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that I haven't messed up the segmentation labels in my transforms\n",
    "dataset_train[0]['seg'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d7c51",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_net.to('cuda')\n",
    "\n",
    "dataloader_train = monai.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    collate_fn = list_data_collate_no_meta\n",
    ")\n",
    "\n",
    "dataloader_valid = monai.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    collate_fn = list_data_collate_no_meta\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(seg_net.parameters(), learning_rate)\n",
    "\n",
    "epoch_number = 0\n",
    "training_losses = [] \n",
    "validation_losses = []\n",
    "preview_index = random.choice(range(len(dataset_valid)))\n",
    "best_validation_loss = 99999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57875d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_epochs = 40\n",
    "while epoch_number < max_epochs:\n",
    "    \n",
    "    print(f\"Epoch {epoch_number+1}/{max_epochs} ...\")\n",
    "    \n",
    "    if (epoch_number%5==0):\n",
    "        preview_seg_net(dataset_valid[preview_index], figsize=(6,6), print_loss=False);\n",
    "    \n",
    "    seg_net.train()\n",
    "    losses = []\n",
    "    for batch in dataloader_train:\n",
    "        imgs = batch['img'].to('cuda')\n",
    "        true_segs = batch['seg'].to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_segs = seg_net(imgs)\n",
    "        loss = dice_loss(predicted_segs, true_segs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    training_loss = np.mean(losses)\n",
    "    training_losses.append([epoch_number, training_loss])\n",
    "    \n",
    "    print(f\"\\ttraining loss: {training_loss}\")\n",
    "\n",
    "    if (epoch_number%5==0):\n",
    "    \n",
    "        seg_net.eval()\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_valid:\n",
    "                imgs = batch['img'].to('cuda')\n",
    "                true_segs = batch['seg'].to('cuda')\n",
    "                predicted_segs = seg_net(imgs)\n",
    "                loss = dice_loss(predicted_segs, true_segs)\n",
    "                losses.append(loss.item())\n",
    "            validation_loss = np.mean(losses)\n",
    "\n",
    "        print(f\"\\tvalidation loss: {validation_loss}\")\n",
    "        \n",
    "        validation_losses.append([epoch_number, validation_loss])\n",
    "        \n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            torch.save(seg_net.state_dict(),f'seg_net_bestval.pth')\n",
    "    \n",
    "    epoch_number +=1\n",
    "\n",
    "del imgs, true_segs, predicted_segs, loss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c948d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Try on a random validation image\n",
    "data_item_index = random.choice(range(len(dataset_valid)))\n",
    "print(data_item_index)\n",
    "data_item = dataset_valid[data_item_index]\n",
    "with torch.no_grad():\n",
    "    preview_seg_net(data_item, show_heatmap=False, show_bdry=True, show_post_processing=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '0016'\n",
    "if (os.path.exists(f'seg_net{run_id}.pth')):\n",
    "    del run_id\n",
    "    raise Exception(\"Please change run_id so you don't overwrite things.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d88987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT CELL; LOAD\n",
    "# seg_net.load_state_dict(torch.load(f'seg_net_bestval.pth'))\n",
    "# seg_net.load_state_dict(torch.load(f'seg_net{run_id}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d86104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT CELL; SAVE\n",
    "torch.save(seg_net.state_dict(),f'seg_net{run_id}.pth') # Save parameters dict\n",
    "torch.save(seg_net,f'seg_net_model{run_id}.pth') # Save entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against_epoch_numbers(epoch_value_pairs, label):\n",
    "    array = np.array(epoch_value_pairs)\n",
    "    plt.plot(array[:,0], array[:,1], label=label)\n",
    "\n",
    "plot_against_epoch_numbers(training_losses, label=\"training\")\n",
    "plot_against_epoch_numbers(validation_losses, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('dice loss')\n",
    "plt.title('seg net training')\n",
    "plt.savefig(f'seg_net_losses{run_id}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
